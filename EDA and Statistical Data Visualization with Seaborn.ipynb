{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset link : https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"columns with unique values have no relation with the output , so better to drop it. e.g 'id' here\n\ncolumns which are 'unnamed' with values'Nan' can also be dropped e.g 'Unnamed: 32' here","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = data.columns\nprint(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To separate the features from the output labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.diagnosis\ndrop_cols = ['Unnamed: 32', 'id','diagnosis']\nx = data.drop(drop_cols , axis =1) # axis =0 is for rows \nx.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### PLOT DIAGNOSIS DRISTRIBUTION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check class imbalance issue\n#seaborn count function \n\nax = sns.countplot(y , label ='Count')\nB, M = y.value_counts()\nprint('Number of Benign Tumors : ',B)\nprint('Number of Malingnant Tumors : ',M)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check statistical values for features, by check it we can depict if standarization/normalization is required or not.\nx.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### VISUALIZAING STANDARDIZED DATA WITH SEABORN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# violin plots , similar to box plot but also shows prob density of the variable\n\n#standarize the data since , it has variations \ndata = x\ndata_std = (data - data.mean())/ data.std()\ndata = pd.concat([y, data_std.iloc[:,0:10]], axis = 1)\n# violin plot, 'data' is in long format which is not supported for violin plot , so we need to melt it\ndata = pd.melt(data, id_vars ='diagnosis',\n              var_name = 'features',  # rest of the features\n              value_name = 'value')   # value of each feature \nplt.figure(figsize =(10,10))\nsns.violinplot( x= 'features', y='value' , hue ='diagnosis', data=data, split =True, inners='quarts')\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be seen that 'fractal_dim' last plot has same shape for both 'B' and 'M' , so this does not given sufficient value for the diagnosis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([y, data_std.iloc[:,10:20]], axis = 1)\n# violin plot, 'data' is in long format which is not supported for violin plot , so we need to melt it\ndata = pd.melt(data, id_vars ='diagnosis',\n              var_name = 'features',  # rest of the features\n              value_name = 'value')   # value of each feature \nplt.figure(figsize =(10,10))\nsns.violinplot( x= 'features', y='value' , hue ='diagnosis', data=data, split =True, inners='quarts')\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([y, data_std.iloc[:,20:30]], axis = 1)\n# violin plot, 'data' is in long format which is not supported for violin plot , so we need to melt it\ndata = pd.melt(data, id_vars ='diagnosis',\n              var_name = 'features',  # rest of the features\n              value_name = 'value')   # value of each feature \nplt.figure(figsize =(10,10))\nsns.violinplot( x= 'features', y='value' , hue ='diagnosis', data=data, split =True, inners='quarts')\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we have two similar distributions like in above plot 'concave points_worst' and 'concavity_worst' , these can negatively affect the prediction output. We need to handle this issue !","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# To check for outliers using Box plot\nsns.boxplot(x='features', y='value', hue='diagnosis', data=data)\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### JOINT PLOTS FOR FEATURE COMPARISON","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"When we have two similar distributions like in above plot 'concave points_worst' and 'concavity_worst' , these can negatively affect the prediction output. We need to handle this issue ! -- addressing this by checking the correlation between them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x.loc[:, 'concavity_worst'],\n             x.loc[:, 'concave points_worst'],\n             kind ='regg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x.loc[:, 'concavity_worst'],\n             x.loc[:, 'area_worst'],\n             kind ='regg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### OBSERVING THE DISTRIBUTION OF VALUES AND THEIR VARIANCE USING SWARM PLOTS","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"swarm plots are affective if the number of data points are small, in this case we have only 600 data points , so swarm plots are more affective in visualizing data than violin plot.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'whitegrid', palette ='muted')\ndata = x\ndata_std = (data - data.mean())/ data.std()\ndata = pd.concat([y, data_std.iloc[:,0:10]], axis = 1)\ndata = pd.melt(data, id_vars ='diagnosis',\n              var_name = 'features',  # rest of the features\n              value_name = 'value')   # value of each feature \nplt.figure(figsize =(10,10))\nsns.swarmplot( x= 'features', y='value' , hue ='diagnosis', data=data)\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'whitegrid', palette ='muted')\ndata = x\ndata_std = (data - data.mean())/ data.std()\ndata = pd.concat([y, data_std.iloc[:,10:20]], axis = 1)\ndata = pd.melt(data, id_vars ='diagnosis',\n              var_name = 'features',  # rest of the features\n              value_name = 'value')   # value of each feature \nplt.figure(figsize =(10,10))\nsns.swarmplot( x= 'features', y='value' , hue ='diagnosis', data=data)\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'whitegrid', palette ='muted')\ndata = x\ndata_std = (data - data.mean())/ data.std()\ndata = pd.concat([y, data_std.iloc[:,20:30]], axis = 1)\ndata = pd.melt(data, id_vars ='diagnosis',\n              var_name = 'features',  # rest of the features\n              value_name = 'value')   # value of each feature \nplt.figure(figsize =(10,10))\nsns.swarmplot( x= 'features', y='value' , hue ='diagnosis', data=data)\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Swarm plots shows that columns where the prediction classes are well separated from each other or not. here 'smoothness_worst' is not well separated all data points are mixed, whereas 'area_worst' is well separated.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### OBSERVING ALL PAIR-WISE CORRELATION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To check the correlation among all columns, we use heat map.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(x.corr() , annot=True, linewidths=1, fmt='.1f', ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FEATURE SELECTION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Method 1: To drop correlated columns from the dataset ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping all columns which have correlation coffecient = 1.0\ndrop_cols = ['radius_mean','perimeter_mean','area_mean','radius_worst','perimeter_worst','area_worst',\n            'compactness_mean', 'compactness_worst','perimeter_se','radius_se','area_se']\n\ndf = x.drop(drop_cols, axis = 1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(df.corr() , annot=True, linewidths=1, fmt='.1f', ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CLASSIFICATION USING XGBOOST (minimal feature selection)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(df , y, test_size = 0.3, random_state=42)\nclf_1 = xgb.XGBClassifier(random_state=42)\nclf_1 = clf_1.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy : \", accuracy_score(y_test, clf_1.predict(x_test)))\ncm = confusion_matrix(y_test, clf_1.predict(x_test))\nsns.heatmap(cm , annot=True, fmt='d')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Method 2 : Univariate feature selection (selects best k features using chi-sqaure test)\n\nNote: chi-square test calculated the dependencies between the random variable in the dataset. So, this statistic will ignore those features which are independent with target class (features irrelevant for prediction).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"select_feature = SelectKBest(chi2 , k=10).fit(x_train, y_train)\nprint(\"Score List: \", select_feature.scores_)\nprint(\"Feature List: \", x_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_2 = select_feature.transform(x_train)\nx_test_2 = select_feature.transform(x_test)\n\nclf_2 = xgb.XGBClassifier(random_state=42)\nclf_2 = clf_1.fit(x_train_2, y_train)\n\nprint(\"Accuracy : \", accuracy_score(y_test, clf_2.predict(x_test_2)))\ncm_2 = confusion_matrix(y_test, clf_2.predict(x_test_2))\nsns.heatmap(cm_2 , annot=True, fmt='d')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Method 3 : Recursive feature elimiation using cross-validation (this method gives best features but also optimal number of features)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\nclf_3 = xgb.XGBClassifier()\nrfecv = RFECV(estimator=clf_3 , step = 1 , cv =5, scoring='accuracy', n_jobs = -1).fit(x_train, y_train)\n#'step': the #features eleminated in each step,\n# 'cv': #cross-validation\n\nprint(\"Optimal no. of features: \", rfecv.n_features_)\nprint(\"Best features: \", x_train.columns[rfecv.support_])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy\" , accuracy_score(y_test, rfecv.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = [i for i in range(1, len(rfecv.grid_scores_)+1)]\ncv_scores= rfecv.grid_scores_\nax = sns.lineplot(x= num_features, y=cv_scores)\nax.set(xlabel = 'No. of selected feature', ylabel ='cv_scores')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Method 4: Using PCA (when dataset has large no. of features, we can reduce the feature space using PCA technique)\n\nNOTE: PCA techniques requires that data to be 0-mean, i.e data should be centered around reference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n\n#normalizing data\nx_train_norm = (x_train-x_train.mean())/ (x_train.max()- x_train.min())\nx_test_norm = (x_test-x_test.mean())/ (x_test.max()- x_test.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA()\npca.fit(x_train_norm)\n\nplt.figure(figsize=(10,8))\nsns.lineplot(data=np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel(\"No. of features\")\nplt.ylabel(\"Cumulative explained variance ratio\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}